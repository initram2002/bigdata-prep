# bigdata-prep

**14-day intensive prep for Big Data Processing and Analytics**

A comprehensive learning repository covering Java/Hadoop MapReduce, PySpark, SQL, and relational modeling with hands-on labs, study notes, and performance benchmarks.

## 🚀 Overview

This repository provides a structured 14-day learning path for mastering big data technologies:
- **Java/Hadoop MapReduce**: Core distributed computing concepts and implementation
- **PySpark**: Python-based Spark programming for large-scale data processing
- **SQL**: Advanced querying techniques for big data environments
- **Relational Modeling**: Database design principles for analytical workloads

## 📁 Repository Structure

```
bigdata-prep/
├── notes/           # Study notes and conceptual materials
├── sql/             # SQL scripts and database schemas
├── java/            # Java MapReduce projects
├── mapreduce/       # Standalone MapReduce examples
├── pyspark/         # PySpark notebooks and scripts
├── reports/         # Performance benchmarks and analysis reports
├── data/sample/     # Sample datasets for practice
├── logs/            # Application and system logs
├── templates/       # Project templates and checklists
└── README.md        # This file
```

## 📅 14-Day Learning Checklist

### Week 1: Foundations
- [ ] **Day 1**: Big Data ecosystem overview and Hadoop architecture
- [ ] **Day 2**: HDFS concepts and command-line operations
- [ ] **Day 3**: MapReduce programming model and Java basics
- [ ] **Day 4**: Implement WordCount in Java MapReduce
- [ ] **Day 5**: Advanced MapReduce patterns (joins, aggregations)
- [ ] **Day 6**: Spark introduction and RDD fundamentals
- [ ] **Day 7**: Week 1 review and hands-on lab

### Week 2: Advanced Topics
- [ ] **Day 8**: PySpark DataFrames and SQL integration
- [ ] **Day 9**: Spark SQL and DataFrame operations
- [ ] **Day 10**: Performance optimization and tuning
- [ ] **Day 11**: Data modeling for analytics workloads
- [ ] **Day 12**: Advanced SQL for big data (window functions, CTEs)
- [ ] **Day 13**: Integration project and benchmarking
- [ ] **Day 14**: Final review and assessment

## 🛠 Prerequisites

- Java 8+ and Maven installed
- Python 3.7+ with Jupyter notebooks
- Hadoop/Spark development environment (local or cluster)
- Basic understanding of SQL and database concepts

## 🚀 Quick Start

1. Clone this repository
2. Set up your development environment
3. Follow the 14-day checklist
4. Use sample data for hands-on practice
5. Complete labs and track progress

## 📊 Sample Projects

- **Java MapReduce WordCount**: Classic distributed word counting
- **PySpark Data Analysis**: Interactive data exploration notebooks
- **SQL Analytics**: Complex queries on large datasets
- **Performance Benchmarks**: Comparative analysis of different approaches

## 📝 License

- Code: Apache License 2.0 (see LICENSE)
- Documentation: CC BY 4.0 (see LICENSE-docs)
